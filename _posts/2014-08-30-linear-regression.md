---
layout: post
title: R语言与多元线性回归
categories: [R]
tags:
- R
- 多元线性回归
---

主要介绍线性回归的方法，用R来实现多元线性回归。

# 回归分析简介

## 相关与回归

变量之间有两种关系。一种是确定性的，也叫**函数关系**；一种是非确定性的，也叫**统计关系**。研究统计关系的方法有**相关分析**和**回归分析**。

相关和回归的区别：

- 回归分析中因变量`y`处于被解释的地位，相关分析中`y`和`x`地位平等
- 回归分析中`y`是随机变量，`x`可以是确定性变量，相关分析中`x`和`y`都是随机变量
- 回归分析可以揭示`x`对`y`影响的大小，相关分析只描述`x`和`y`的线性关系

## 简单线性回归方程

`y=a+bx`

`a`和`b`称为经验回归系数

### 随机误差项

随机误差项是由于人的认知以及其他客观原因的局限而没有考虑的偶然因素

### 基本假设

1. G—M条件，误差项同方差和无自相关
2. 误差项正态分布
3. 样本量大于自变量个数

## 回归分析一般步骤

1. 设立变量
2. 处理数据
3. 确定回归模型
4. 参数估计
5. 模型检验
6. 应用回归模型

统计检验包括*回归方程的显著性检验*，*回归系数的显著性检验*，*拟合优度检验*，*随机误差的自相关检验和异反差检验*，*自变量的多重共线性检验*等

# 一元线性回归

一般用最小二乘和最大似然估计作为回归参数的估计值。最小二乘是使**离差平方和**最小

# 多元线性回归

多元线性回归方法和一元一样，只不过自变量多了，参数也多了
由于贴图片不太容易，这里就只总结几个常用的函数

## 常用函数

- 变量间线性相关系数`cor(dataframe)`
- 散点图矩阵`scatterplotMatrix(dataframe)`
- 线性拟合

{% highlight r %}
> fit=lm(y ~ x1 + x2 + x3 ..., data = dataframe)
> summary(fit)
{% endhighlight %}

- 残差的正态性检验

{% highlight r %}
> library(car)
> qqPlot(fit)
{% endhighlight %}

- 残差的独立性检验`durbinWatsonTest(fit)`
- 自变量和因变量的线性关系检验`crPlots(fit)`
- 同方差性检验`ncvTest(fit)`和建议幂次转换(y)`spreadLevelPlot(fit)`
- 多重共线性检验

{% highlight r %}
> vif(fit)
> sqrt(vif(fit)) > 2 #全为FALSE无共线性
{% endhighlight %}

## 改进措施

处理违背回归假设的方法
1. 删除观测点
2. 变量变换
3. 增删变量
4. 其他回归方法

## 变量选择

一般采用逐步回归法

{% highlight r %}
> library(MASS)
> stepAIC(fit, direction = "both")
{% endhighlight %}

注：
fit全为`fit = lm(y ~ x1 + x2 + x3 ..., data = dataframe)`
